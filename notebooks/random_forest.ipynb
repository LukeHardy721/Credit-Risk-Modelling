{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dece71ac",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2c7f4",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b677bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076248, 80)\n",
      "(269062, 80)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"../data/train_non_lin_preprocessed.parquet\")\n",
    "print(train_df.shape)\n",
    "\n",
    "X_train = train_df.drop(columns = ['target'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "test_df = pd.read_parquet(\"../data/test_non_lin_preprocessed.parquet\")\n",
    "print(test_df.shape)\n",
    "\n",
    "X_test = test_df.drop(columns = ['target'])\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b97589",
   "metadata": {},
   "source": [
    "## Imbalanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_col = \"target\"\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.7207610799635567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    215350\n",
      "           1       0.58      0.06      0.12     53712\n",
      "\n",
      "    accuracy                           0.80    269062\n",
      "   macro avg       0.69      0.53      0.50    269062\n",
      "weighted avg       0.76      0.80      0.74    269062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f48e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mplot_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mplot_feature_importances\u001b[1;34m(rf)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Sort by importance\u001b[39;00m\n\u001b[0;32m      7\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m importances\u001b[38;5;241m.\u001b[39margsort()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), importances[sorted_idx])\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), feature_names[sorted_idx], rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_feature_importances(rf):\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Sort by importance\n",
    "    sorted_idx = importances.argsort()[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(range(len(importances)), importances[sorted_idx])\n",
    "    plt.xticks(range(len(importances)), feature_names[sorted_idx], rotation=90)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importances(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b3103",
   "metadata": {},
   "source": [
    "## Balanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee82f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96cbd15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.7181692997191498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79    215350\n",
      "           1       0.34      0.59      0.43     53712\n",
      "\n",
      "    accuracy                           0.69    269062\n",
      "   macro avg       0.61      0.65      0.61    269062\n",
      "weighted avg       0.77      0.69      0.72    269062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fa4eace",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mplot_feature_importances\u001b[1;34m(rf)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Sort by importance\u001b[39;00m\n\u001b[0;32m      7\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m importances\u001b[38;5;241m.\u001b[39margsort()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), importances[sorted_idx])\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), feature_names[sorted_idx], rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plot_feature_importances(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abebbc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.3848263435995586\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d9b7e",
   "metadata": {},
   "source": [
    "Note that this gives a similar ROC AUC, but is much better on the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06c01f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b954f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd892c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5}\n",
      "Best ROC AUC: 0.7165833109563081\n"
     ]
    }
   ],
   "source": [
    "# rf_model = RandomForestClassifier(\n",
    "#     n_estimators=25,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     class_weight='balanced'  # Handle imbalance\n",
    "# )\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# param_grid = {\n",
    "#     'max_depth': [10, 20],  # None = expand fully\n",
    "#     'max_features': ['sqrt', 'log2'], # features per split\n",
    "#     'min_samples_split': [5, 10]   # control overfitting\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=rf_model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='roc_auc',  # optimize for AUC\n",
    "#     cv=cv,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best ROC AUC:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4751ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.716935230809707\n"
     ]
    }
   ],
   "source": [
    "# best_rf = grid_search.best_estimator_\n",
    "# y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "# print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee848c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_importances(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20ae9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.38296485791741053\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01773d62",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b99821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77315670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 4.00936945826565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:03:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lukeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:03:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ROC AUC: 0.7352468432020971\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=400,        # number of trees\n",
    "    max_depth=5,            # depth of trees\n",
    "    learning_rate=0.1,       # shrinkage\n",
    "    subsample=0.8,           # row sampling\n",
    "    colsample_bytree=0.8,    # feature sampling\n",
    "    scale_pos_weight=scale_pos_weight,  # handle imbalance\n",
    "    eval_metric='auc',       # track ROC AUC\n",
    "    tree_method='gpu_hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(\"XGBoost ROC AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e61890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.40681454972520753\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fb646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.29\n",
      "Min expected cost: 188056\n"
     ]
    }
   ],
   "source": [
    "cost_fn = 10  # relative cost\n",
    "cost_fp = 1\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_threshold, best_cost = 0, float('inf')\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_proba >= t).astype(int)\n",
    "    FN = np.sum((y_test==1) & (y_pred==0))\n",
    "    FP = np.sum((y_test==0) & (y_pred==1))\n",
    "    cost = FN*cost_fn + FP*cost_fp\n",
    "    \n",
    "    if cost < best_cost:\n",
    "        best_cost = cost\n",
    "        best_threshold = t\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Min expected cost:\", best_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f99f98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (\u001b[43my_proba\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_proba' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "y_pred = (y_proba >= 0.45).astype(int) # 5:1 cost_fn:cost_fp\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "y_pred = (y_proba >= 0.29).astype(int) # 10:1 cost_fn:cost_fp\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "y_pred = (y_proba >= 0.18).astype(int) # 20:1 cost_fn:cost_fp\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b204b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m(y_test, y_proba)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr, tpr, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"XGBoost ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc7afa",
   "metadata": {},
   "source": [
    "XGBoost is too computationally intense to tune hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
